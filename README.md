# InterpretableDoubleDescent
DSC 261 Responsible Data Science Project

Collaborators:
* Adarsh Vemali
* Adhvaith Vijay
* Laurel Li

This project used the MNIST-1D dataset to delve into the Double Descent phenomenon in deep learning (specifically neural networks), and interpretatively analyzed how data points and model complexity affect model performance using SHAP, LIME and Saliency maps.

Baseline:
We utilised the PyTorch framework for our analysis. The attached code, provided by Sam Greydanus of Windscape AI,  served as the base for our exploration, and can be found https://colab.research.google.com/github/greydanus/mnist1d/blob/master/quickstart.ipynb, gave us the foundation for an implementation of 2 layer neural network model with varying number of neurons.
